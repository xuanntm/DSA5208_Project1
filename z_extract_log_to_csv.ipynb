{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mpi_world_size global_train_size local_sizes train_loop_time batch_size  \\\n",
      "0               8          25923545     3240444         67.9855       2048   \n",
      "1               8          25923545     3240444         63.4918        128   \n",
      "2              12          25923540     2160295         52.9933       1024   \n",
      "3              16          25923545     1620222        121.6935       1024   \n",
      "4              16          25923545     1620222        356.0124       1024   \n",
      "5               8          25923545     3240444         85.5563        512   \n",
      "6              16          25923545     1620222         54.4048       1024   \n",
      "7               8          25923545     3240444         93.5340        256   \n",
      "8               8          25923545     3240444         89.9634       2048   \n",
      "9               8          25923545     3240444        143.4612       2048   \n",
      "10              8          25923545     3240444        146.8688        512   \n",
      "11              8          25923545     3240444        146.8923        256   \n",
      "12              8          25923545     3240444         85.3933       1024   \n",
      "13              8          25923545     3240444        142.0473       1024   \n",
      "14              8          25923545     3240444         96.9161       1024   \n",
      "15              8          25923545     3240444        159.8392       1024   \n",
      "16              8          25923545     3240444        254.5867       1024   \n",
      "17              8          25923545     3240444        145.8775        128   \n",
      "18              8          25923545     3240444        484.7968       1024   \n",
      "19              8          25923545     3240444        418.9945       1024   \n",
      "20              8          25923545     3240444         68.5522        256   \n",
      "21              8          25923545     3240444         67.4855       1024   \n",
      "22              8          25923545     3240444        131.8010       1024   \n",
      "23              8          25923545     3240444         70.1331        512   \n",
      "24              8          25923545     3240444        223.4623       1024   \n",
      "25              8          25923545     3240444         96.7935        128   \n",
      "26              8          25923545     3240444        224.8233       1024   \n",
      "\n",
      "   hidden     lr activation seed sync_every epochs total_iters train_time  \\\n",
      "0      64  0.002       relu  123          0      1        1583     67.987   \n",
      "1      64  0.002       relu  123          0      1       25316     63.493   \n",
      "2      64  0.002       relu  123          0      1        2110     52.995   \n",
      "3      64  0.002       relu  123          0      2        3166    121.700   \n",
      "4      64  0.002       relu  123          0      5        7915    356.024   \n",
      "5      64  0.002       tanh  123          0      1        6329     85.576   \n",
      "6      64  0.002       relu  123          0      1        1583     54.432   \n",
      "7      64  0.002       tanh  123          0      1       12658     93.537   \n",
      "8      64  0.002       tanh  123          0      1        1583     89.965   \n",
      "9      64  0.002    sigmoid  123          0      1        1583    143.465   \n",
      "10     64  0.002    sigmoid  123          0      1        6329    146.871   \n",
      "11     64  0.002    sigmoid  123          0      1       12658    146.894   \n",
      "12     64  0.002       relu  123       1000      1        3165     85.395   \n",
      "13     64  0.002    sigmoid  123          0      1        3165    142.051   \n",
      "14     64  0.002       tanh  123          0      1        3165     96.918   \n",
      "15     64  0.002       tanh  123          0      3        9495    159.850   \n",
      "16     64  0.002    sigmoid  123          0      3        9495    254.590   \n",
      "17     64  0.002    sigmoid  123          0      1       25316    145.880   \n",
      "18     64  0.002       tanh  123          0      5       15825    484.800   \n",
      "19     64  0.002    sigmoid  123          0      5       15825    418.999   \n",
      "20     64  0.002       relu  123          0      1       12658     68.555   \n",
      "21     64  0.002       relu  123          0      1        3165     67.488   \n",
      "22     64  0.002       relu  123          0      3        9495    131.808   \n",
      "23     64  0.002       relu  123          0      1        6329     70.134   \n",
      "24     96  0.002       relu  123          0      1        3165    223.465   \n",
      "25     64  0.002       tanh  123          0      1       25316     96.798   \n",
      "26     64  0.002       relu  123          0      5       15825    224.827   \n",
      "\n",
      "   rmse_train  rmse_test run_training_time  \\\n",
      "0   16.253561  16.251801           83.7082   \n",
      "1   16.465376  16.461931           76.8835   \n",
      "2   18.110921  18.086124           67.0841   \n",
      "3    4.102503   4.092289          136.6759   \n",
      "4    3.833969   3.824173          369.3965   \n",
      "5   17.809660  17.807883          104.9865   \n",
      "6   18.830995  18.819300           70.1238   \n",
      "7   17.544658  17.542964          111.3963   \n",
      "8   18.143578  18.142074          108.0294   \n",
      "9    7.313906   7.321268          166.1092   \n",
      "10   7.553946   7.560539          171.5847   \n",
      "11   7.734345   7.740521          170.1526   \n",
      "12   3.961258   3.968538          104.0165   \n",
      "13   7.440675   7.447601          165.1613   \n",
      "14  17.989523  17.987865          117.2133   \n",
      "15   3.654242   3.663107          178.6667   \n",
      "16   3.827903   3.836547          279.6447   \n",
      "17   8.028142   8.033704          169.6367   \n",
      "18   3.555706   3.564052          502.3659   \n",
      "19   3.755140   3.763639          442.7666   \n",
      "20  16.367395  16.364344           83.5315   \n",
      "21  16.367756  16.365548           85.3176   \n",
      "22   3.772928   3.780973          147.3362   \n",
      "23  16.380898  16.378312           84.7269   \n",
      "24  17.486019  17.482813          267.3359   \n",
      "25  17.102208  17.100584          116.2536   \n",
      "26   3.713229   3.721180          240.1412   \n",
      "\n",
      "                                       file  \n",
      "0                 rank0_relu2048_epoch1.log  \n",
      "1                  rank0_relu128_epoch1.log  \n",
      "2       rank0_relu1024_epoch1_process12.log  \n",
      "3       rank0_relu1024_epoch2_process16.log  \n",
      "4       rank0_relu1024_epoch5_process16.log  \n",
      "5                  rank0_tanh512_epoch1.log  \n",
      "6       rank0_relu1024_epoch1_process16.log  \n",
      "7                  rank0_tanh256_epoch1.log  \n",
      "8                 rank0_tanh2048_epoch1.log  \n",
      "9              rank0_sigmoid2048_epoch1.log  \n",
      "10              rank0_sigmoid512_epoch1.log  \n",
      "11              rank0_sigmoid256_epoch1.log  \n",
      "12  rank0_relu1024_epoch1_syncevery1000.log  \n",
      "13             rank0_sigmoid1024_epoch1.log  \n",
      "14                rank0_tanh1024_epoch1.log  \n",
      "15                rank0_tanh1024_epoch3.log  \n",
      "16             rank0_sigmoid1024_epoch3.log  \n",
      "17              rank0_sigmoid128_epoch1.log  \n",
      "18                rank0_tanh1024_epoch5.log  \n",
      "19             rank0_sigmoid1024_epoch5.log  \n",
      "20                 rank0_relu256_epoch1.log  \n",
      "21                rank0_relu1024_epoch1.log  \n",
      "22                rank0_relu1024_epoch3.log  \n",
      "23                 rank0_relu512_epoch1.log  \n",
      "24       rank0_relu1024_epoch1_hidden96.log  \n",
      "25                 rank0_tanh128_epoch1.log  \n",
      "26                rank0_relu1024_epoch5.log  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Regex patterns\n",
    "patterns = {\n",
    "    \"mpi_world_size\": re.compile(r\"MPI world size:\\s+(\\d+)\"),\n",
    "    \"train_size\": re.compile(r\"Global train size:\\s+(\\d+), local sizes:\\s+(\\d+)\"),\n",
    "    \"train_loop_time\": re.compile(r\"Training Loop===== took ([\\d\\.]+) sec\"),\n",
    "    \"epochs\": re.compile(r\"Epochs:\\s+(\\d+), total iters:\\s+(\\d+)\"),\n",
    "    \"train_time\": re.compile(r\"Training time \\(s\\):\\s+([\\d\\.]+)\"),\n",
    "    \"rmse_train\": re.compile(r\"RMSE train:\\s+([\\d\\.]+)\"),\n",
    "    \"rmse_test\": re.compile(r\"RMSE test:\\s+([\\d\\.]+)\"),\n",
    "    \"run_training_time\": re.compile(r\"run training took ([\\d\\.]+) sec\"),\n",
    "    \"namespace\": re.compile(\n",
    "        r\"batch_size=(\\d+), hidden=(\\d+), lr=([\\d\\.]+), activation='(\\w+)', seed=(\\d+), sync_every=(\\d+)\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "def parse_log_file(file_path):\n",
    "    results = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            for key, pattern in patterns.items():\n",
    "                match = pattern.search(line)\n",
    "                if match:\n",
    "                    if key == \"namespace\":\n",
    "                        results[\"batch_size\"], results[\"hidden\"], results[\"lr\"], results[\"activation\"], results[\"seed\"], results[\"sync_every\"] = match.groups()\n",
    "                    elif key == \"epochs\":\n",
    "                        results[\"epochs\"], results[\"total_iters\"] = match.groups()\n",
    "                    elif key == \"train_size\":\n",
    "                        results[\"global_train_size\"], results[\"local_sizes\"] = match.groups()\n",
    "                    else:\n",
    "                        results[key] = match.groups()[0] if len(match.groups()) == 1 else match.groups()\n",
    "    return results\n",
    "\n",
    "# Read all log files\n",
    "log_dir = Path(\"logs/\")  # change to your log folder\n",
    "data = []\n",
    "\n",
    "for file in log_dir.glob(\"*.log\"):\n",
    "    parsed = parse_log_file(file)\n",
    "    parsed[\"file\"] = file.name\n",
    "    data.append(parsed)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"report/log_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              filename  epoch  Iter  local_R_theta\n",
      "0            rank0_relu1024_epoch1.log      0   310      12.377288\n",
      "1            rank0_relu1024_epoch1.log      0   620      10.239742\n",
      "2            rank0_relu1024_epoch1.log      0   930       9.263220\n",
      "3            rank0_relu1024_epoch1.log      0  1240       8.698991\n",
      "4            rank0_relu1024_epoch1.log      0  1550       8.326568\n",
      "5            rank0_relu1024_epoch1.log      0  1860       8.045514\n",
      "6            rank0_relu1024_epoch1.log      0  2170       7.869802\n",
      "7            rank0_relu1024_epoch1.log      0  2480       7.696306\n",
      "8            rank0_relu1024_epoch1.log      0  2790       7.571086\n",
      "9            rank0_relu1024_epoch1.log      0  3100       7.472262\n",
      "10  rank0_relu1024_epoch1_hidden96.log      0   310      12.199092\n",
      "11  rank0_relu1024_epoch1_hidden96.log      0   620      10.087094\n",
      "12  rank0_relu1024_epoch1_hidden96.log      0   930       9.135259\n",
      "13  rank0_relu1024_epoch1_hidden96.log      0  1240       8.559051\n",
      "14  rank0_relu1024_epoch1_hidden96.log      0  1550       8.195326\n",
      "15  rank0_relu1024_epoch1_hidden96.log      0  1860       7.924100\n",
      "16  rank0_relu1024_epoch1_hidden96.log      0  2170       7.736059\n",
      "17  rank0_relu1024_epoch1_hidden96.log      0  2480       7.556971\n",
      "18  rank0_relu1024_epoch1_hidden96.log      0  2790       7.434162\n",
      "19  rank0_relu1024_epoch1_hidden96.log      0  3100       7.337446\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Regex to match history log lines\n",
    "history_pattern = re.compile(\n",
    "    r\"Iter\\s+(\\d+), epoch\\s+(\\d+), local R\\(θ\\)=([\\d\\.]+)\"\n",
    ")\n",
    "\n",
    "def parse_history(file_path):\n",
    "    rows = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            match = history_pattern.search(line)\n",
    "            if match:\n",
    "                iteration, epoch, local_r = match.groups()\n",
    "                rows.append({\n",
    "                    \"filename\": file_path.name,\n",
    "                    \"epoch\": int(epoch),\n",
    "                    \"Iter\": int(iteration),\n",
    "                    \"local_R_theta\": float(local_r)\n",
    "                })\n",
    "    return rows\n",
    "\n",
    "def main():\n",
    "    log_dir = Path(\"logs/\")  # change to your logs folder\n",
    "    all_rows = []\n",
    "\n",
    "    for file in log_dir.glob(\"*.log\"):\n",
    "        all_rows.extend(parse_history(file))\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_rows)\n",
    "\n",
    "    # Order by filename, epoch, Iter\n",
    "    df = df.sort_values(by=[\"filename\", \"epoch\", \"Iter\"]).reset_index(drop=True)\n",
    "\n",
    "    print(df.head(20))  # preview\n",
    "    df.to_csv(\"report/log_history.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Plots saved as <filename>_history.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the extracted CSV from previous script\n",
    "df = pd.read_csv(\"report/log_history.csv\")\n",
    "\n",
    "# Plot for each file separately\n",
    "for filename, group in df.groupby(\"filename\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(group[\"Iter\"], group[\"local_R_theta\"], marker=\"o\", linestyle=\"-\")\n",
    "    \n",
    "    plt.title(filename)  # chart title\n",
    "    plt.xlabel(\"Iter\")\n",
    "    plt.ylabel(\"local R(θ)\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    \n",
    "    # Save each chart\n",
    "    os.makedirs(os.path.join(\"charts\",\"history\"), exist_ok=True)\n",
    "    plt.savefig(f\"charts/history/{filename}_history.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"✅ Plots saved as <filename>_history.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load summary data\n",
    "df = pd.read_csv(\"report/log_summary.csv\")\n",
    "\n",
    "def plot_metric(df, metric, epoch_filter, mpi_world_size_filter=8, sync_every_filter=0, hidden_filter=64):\n",
    "    # Filter by epoch\n",
    "    data = df[(df[\"epochs\"] == epoch_filter) & (df[\"mpi_world_size\"] == mpi_world_size_filter) & (df[\"sync_every\"] == sync_every_filter) & (df[\"hidden\"] == hidden_filter)]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot each activation as separate line\n",
    "    for activation, group in data.groupby(\"activation\"):\n",
    "        # Sort by batch_size before plotting\n",
    "        group = group.sort_values(\"batch_size\")\n",
    "\n",
    "        plt.plot(\n",
    "            group[\"batch_size\"], \n",
    "            group[metric], \n",
    "            marker=\"o\", \n",
    "            linestyle=\"-\", \n",
    "            label=activation\n",
    "        )\n",
    "\n",
    "    plt.title(f\"{metric} vs batch_size (epochs={epoch_filter})\")\n",
    "    plt.xlabel(\"Batch Size\")\n",
    "    plt.ylabel(metric.replace(\"_\", \" \").title())\n",
    "    plt.legend(title=\"Activation\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    os.makedirs(os.path.join(\"charts\",\"result\"), exist_ok=True)\n",
    "    plt.savefig(f\"charts/result/{metric}_epochs{epoch_filter}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Example usage:\n",
    "for metric in [\"rmse_train\", \"rmse_test\", \"run_training_time\"]:\n",
    "    plot_metric(df, metric, epoch_filter=1, mpi_world_size_filter=8, sync_every_filter=0, hidden_filter=64)   # change epoch value as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load summary data\n",
    "df = pd.read_csv(\"report/log_summary.csv\")\n",
    "\n",
    "def plot_metric_by_batch(df, metric, batch_size_filter=1024, mpi_world_size_filter=8, sync_every_filter=0, hidden_filter=64):\n",
    "    # Filter by batch_size\n",
    "    data = df[(df[\"batch_size\"] == batch_size_filter) & (df[\"mpi_world_size\"] == mpi_world_size_filter) & (df[\"sync_every\"] == sync_every_filter) & (df[\"hidden\"] == hidden_filter)]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot each activation as separate line\n",
    "    for activation, group in data.groupby(\"activation\"):\n",
    "        # Sort by epochs before plotting\n",
    "        group = group.sort_values(\"epochs\")\n",
    "\n",
    "        plt.plot(\n",
    "            group[\"epochs\"], \n",
    "            group[metric], \n",
    "            marker=\"o\", \n",
    "            linestyle=\"-\", \n",
    "            label=activation\n",
    "        )\n",
    "\n",
    "    plt.title(f\"{metric} vs epochs (batch_size={batch_size_filter})\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric.replace(\"_\", \" \").title())\n",
    "    plt.legend(title=\"Activation\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    os.makedirs(os.path.join(\"charts\",\"result\"), exist_ok=True)\n",
    "    plt.savefig(f\"charts/result/{metric}_b{batch_size_filter}_p{mpi_world_size_filter}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Example usage:\n",
    "for metric in [\"rmse_train\", \"rmse_test\", \"run_training_time\"]:\n",
    "    plot_metric_by_batch(df, metric, batch_size_filter=1024, mpi_world_size_filter=8)  # default batch_size\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
